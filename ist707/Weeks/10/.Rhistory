# Create a histogram of durations (appears in the Plots tab)
hist(sqlResult$ActualDuration,
main="How long are the VidCasts?",
xlab="Minutes",
ylab="VidCasts",
border="blue",
col="grey",
labels=TRUE
)
# Plot a bar chart of video counts by day of the week
dayCounts <- table(sqlResult$StartDayOfWeek)
barplot(dayCounts,
main="VidCasts by Day of Week",
ylab="Day of Week",
xlab="Count of VidCasts",
names.arg = days
)
DBI::dbDisconnect(myconn)
#install.packages("odbc")
library(odbc)
# Create a connection to SQL Server using ODBC
# NOTE: Be sure to change the database to your actual database
myconn <- DBI::dbConnect(odbc::odbc(),
Driver             = "SQL Server Native Client 11.0",
Server             = ".",
Database           = "IST659",
Trusted_Connection = "Yes"
)
myconn
# Ready the SQL to send to the Server
sqlSelectStatement <-
"SELECT
vc_VidCast.vc_VidCastID
, vc_VidCast.VidCastTitle
, DATEPART(dw, StartDateTime) as StartDayOfWeek
, DATEDIFF(n, StartDateTime, EndDateTime) as ActualDuration
, ScheduleDurationMinutes
, vc_User.vc_UserID
, vc_User.UserName
FROM vc_VidCast
JOIN vc_User ON vc_User.vc_UserID = vc_VidCast.vc_UserID
"
sqlResult <- dbGetQuery(myconn, sqlSelectStatement)
sqlResult
install.packages("odbc")
install.packages("odbc")
#install.packages("odbc")
library(odbc)
# Create a connection to SQL Server using ODBC
# NOTE: Be sure to change the database to your actual database
myconn <- DBI::dbConnect(odbc::odbc(),
Driver             = "SQL Server Native Client 11.0",
Server             = ".",
Database           = "IST659",
Trusted_Connection = "Yes"
)
# Create a connection to SQL Server using ODBC
# NOTE: Be sure to change the database to your actual database
myconn <- DBI::dbConnect(odbc::odbc(),
Driver             = "SQL Server Native Client 11.0",
Server             = ".",
Database           = "IST6   59",
Trusted_Connection = "Yes"
)
myconn
# Create a connection to SQL Server using ODBC
# NOTE: Be sure to change the database to your actual database
myconn <- DBI::dbConnect(odbc::odbc(),
Driver             = "SQL Server Native Client 11.0",
Server             = ".",
Database           = "IST659",
Trusted_Connection = "Yes"
)
myconn
# Ready the SQL to send to the Server
sqlSelectStatement <-
"SELECT
vc_VidCast.vc_VidCastID
, vc_VidCast.VidCastTitle
, DATEPART(dw, StartDateTime) as StartDayOfWeek
, DATEDIFF(n, StartDateTime, EndDateTime) as ActualDuration
, ScheduleDurationMinutes
, vc_User.vc_UserID
, vc_User.UserName
FROM vc_VidCast
JOIN vc_User ON vc_User.vc_UserID = vc_VidCast.vc_UserID
"
sqlResult <- dbGetQuery(myconn, sqlSelectStatement)
sqlResult
# Use +/- 3 sigma to prune outliers (Symmetrically distributed)
sqlResult <- subset(sqlResult, ActualDuration > 0)
sigma <- sd(sqlResult$ActualDuration)
mu <- mean(sqlResult$ActualDuration)
upper <- mu + (3*sigma)
lower <- mu - (3*sigma)
sqlResult <- subset(sqlResult, ActualDuration < upper)
sqlResult <- subset(sqlResult, ActualDuration > lower)
# Create a list of days of the week for charting later
days <- c("Sun", "Mon", "Tues", "Weds", "Thurs", "Fri", "Sat")
# Create a histogram of durations (appears in the Plots tab)
hist(sqlResult$ActualDuration,
main="How long are the VidCasts?",
xlab="Minutes",
ylab="VidCasts",
border="blue",
col="grey",
labels=TRUE
)
# Plot a bar chart of video counts by day of the week
dayCounts <- table(sqlResult$StartDayOfWeek)
barplot(dayCounts,
main="VidCasts by Day of Week",
ylab="Day of Week",
xlab="Count of VidCasts",
names.arg = days
)
DBI::dbDisconnect(myconn)
library(tm)
pakages.install("tm")
packages.install("tm")
install.packages("tm")
library(wordcloud)
packages.install("tm")
packages.install("wordcloud")
install.packages("wordcloud")
install.packages("tidyr")
install.packages("tidytext")
install.packages("dplyr")
library(tm)
library(wordcloud)
library(tidyr)
library(tidytext)
library(dplyr)
library(farff)
setwd("~/Downloads")
file<-"deception_data_converted_final.csv"
fileData <- read.csv(file)
setwd("D:/Downloads")
file<-"deception_data_converted_final.csv"
fileData <- read.csv(file)
fileData <- read.csv(file, col_names=TRUE, quote="'")
fileData <- read_csv(file, col_names=TRUE, quote="'")
install.packages("readr")
library(readr)
fileData <- read_csv(file, col_names=TRUE, quote="'")
View(fileData)
View(sqlResult)
View(fileData)
str(fileData)
View(fileData)
library(readr)
library(randomForest)
# Code courtesy of https://rpubs.com/meisenbach/284590 by Mei Eisenbach
install.packages("randomForest")
install.packages("nnet")
#install.packages("readr")
#install.packages("randomForest")
#install.packages("nnet")
library(readr)
library(randomForest)
library(nnet)
setwd("C:\\Users\\gregb\\OneDrive\\git\\iSchool\\ist707\\Weeks\\10")
train_orig <- read_csv("digit_train.csv")
test_orig <- read_csv("digit_test.csv")
# save the training labels
train_orig_labels <- train_orig[, 1]
train_orig_labels <- as.factor(train_orig_labels$label)
summary(train_orig_labels)
barplot(table(train_orig[,1]), col=rainbow(10, 0.5), main="n Digits in Train")
# There is around 4000 observations for each digit. Each row has 784 columns
# (pixels) which form a 28x28 image. Let's see what the handwritten digits look
# like by plotting them. Here is a function to plot a selection of digits from
# the train dataset.
plotTrain <- function(images, ){
op <- par(no.readonly=TRUE)
x <- ceiling(sqrt(length(images)))
par(mfrow=c(x, x), mar=c(.1, .1, .1, .1))
for (i in images){ #reverse and transpose each matrix to rotate images
m <- matrix(data.matrix(train_orig[i,-1]), nrow=28, byrow=TRUE)
m <- apply(m, 2, rev)
image(t(m), col=grey.colors(255), axes=FALSE)
text(0.05, 0.2, col="white", cex=1.2, train_orig[i, 1])
}
par(op) #reset the original graphics parameters
}
# There is around 4000 observations for each digit. Each row has 784 columns
# (pixels) which form a 28x28 image. Let's see what the handwritten digits look
# like by plotting them. Here is a function to plot a selection of digits from
# the train dataset.
plotTrain <- function(images){
op <- par(no.readonly=TRUE)
x <- ceiling(sqrt(length(images)))
par(mfrow=c(x, x), mar=c(.1, .1, .1, .1))
for (i in images){ #reverse and transpose each matrix to rotate images
m <- matrix(data.matrix(train_orig[i,-1]), nrow=28, byrow=TRUE)
m <- apply(m, 2, rev)
image(t(m), col=grey.colors(255), axes=FALSE)
text(0.05, 0.2, col="white", cex=1.2, train_orig[i, 1])
}
par(op) #reset the original graphics parameters
}
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36)
# first we are going to try a random forest
numTrees <- 25
# Train on entire training dataset and predict on the test
startTime <- proc.time()
rf <- randomForest(train_orig[-1], train_orig_labels, xtest=test_orig, ntree=numTrees)
proc.time() - startTime
print(rf)
plot(rf)
plot(rf,type="1")
plot(rf,type="l")
varImpPlot(rf)
varImp(rf)
View(rf)
##   user  system elapsed
## 165.52    6.52  207.74
install.packages("party")
library(party)
plot(rf,type="simple")
# output predictions for submission
predictions <- data.frame(ImageId=1:nrow(test_orig),
Label=levels(train_orig_labels)[rf$test$predicted])
head(predictions)
rotate <- function(x) t(apply(x, 2, rev)) # reverses (rotates the matrix)
par(mfrow=c(2,3)) # Plotting in 2*3 format (random forest)
lapply(1:6,
function(x) image( #norow = 28 because this is 28 pixel image
rotate(matrix(unlist(test_orig[x,]),nrow = 28,byrow = T)),
col=grey.colors(255),
xlab=predictions[x,2]
)
)
par(mfrow=c(2,3)) # Plotting in 2*3 format (random forest)
lapply(1:6,
function(x) image( #norow = 28 because this is 28 pixel image
rotate(matrix(unlist(test_orig[x,]),nrow = 28,byrow = T)),
col=grey.colors(255),
xlab=predictions[x,2]
)
)
accuracy <- mean(predictions == test_labels)
View(predictions)
View(test_orig)
View(test_orig)
test_orig.label
head(test_orig)
str(test_orig)
View(predictions)
# There is around 4000 observations for each digit. Each row has 784 columns
# (pixels) which form a 28x28 image. Let's see what the handwritten digits look
# like by plotting them. Here is a function to plot a selection of digits from
# the train dataset.
plotTrain <- function(images, ds){
op <- par(no.readonly=TRUE)
x <- ceiling(sqrt(length(images)))
par(mfrow=c(x, x), mar=c(.1, .1, .1, .1))
for (i in images){ #reverse and transpose each matrix to rotate images
m <- matrix(data.matrix(ds[i,-1]), nrow=28, byrow=TRUE)
m <- apply(m, 2, rev)
image(t(m), col=grey.colors(255), axes=FALSE)
text(0.05, 0.2, col="white", cex=1.2, train_orig[i, 1])
}
par(op) #reset the original graphics parameters
}
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36, test_orig)
# There is around 4000 observations for each digit. Each row has 784 columns
# (pixels) which form a 28x28 image. Let's see what the handwritten digits look
# like by plotting them. Here is a function to plot a selection of digits from
# the train dataset.
plotTrain <- function(images, ds){
op <- par(no.readonly=TRUE)
x <- ceiling(sqrt(length(images)))
par(mfrow=c(x, x), mar=c(.1, .1, .1, .1))
for (i in images){ #reverse and transpose each matrix to rotate images
m <- matrix(data.matrix(ds[i,-1]), nrow=28, byrow=TRUE)
m <- apply(m, 2, rev)
image(t(m), col=grey.colors(255), axes=FALSE)
text(0.05, 0.2, col="white", cex=1.2, ds[i, 1])
}
par(op) #reset the original graphics parameters
}
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36, test_orig)
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36, train_orig)
View(train_orig)
str(train_orig)
plotTrain(1:36, test_orig)
c(2,0,9,0,3,7,0,3,0,3,5,7,4,0,4,3,3,1,9,0,9,1,1,5,7,4,2,7,4,7,7,5,4,2,6,2)
test_orig.label <- c(2,0,9,0,3,7,0,3,0,3,5,7,4,0,4,3,3,1,9,0,9,1,1,5,7,4,2,7,4,7,7,5,4,2,6,2)
text(0.05, 0.2, col="white", cex=1.2, ds[i, "label"])
# There is around 4000 observations for each digit. Each row has 784 columns
# (pixels) which form a 28x28 image. Let's see what the handwritten digits look
# like by plotting them. Here is a function to plot a selection of digits from
# the train dataset.
plotTrain <- function(images, ds){
op <- par(no.readonly=TRUE)
x <- ceiling(sqrt(length(images)))
par(mfrow=c(x, x), mar=c(.1, .1, .1, .1))
for (i in images){ #reverse and transpose each matrix to rotate images
m <- matrix(data.matrix(ds[i,-1]), nrow=28, byrow=TRUE)
m <- apply(m, 2, rev)
image(t(m), col=grey.colors(255), axes=FALSE)
text(0.05, 0.2, col="white", cex=1.2, ds[i, "label"])
}
par(op) #reset the original graphics parameters
}
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36, train_orig)
plotTrain(1:36, test_orig)
test_orig.label <- c(2,0,9,0,3,7,0,3,0,3,5,7,4,0,4,3,3,1,9,0,9,1,1,5,7,4,2,7,4,7,7,5,4,2,6,2)
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36, train_orig)
plotTrain(1:36, test_orig)
str(test_orig)
test_orig$label <- c(2,0,9,0,3,7,0,3,0,3,5,7,4,0,4,3,3,1,9,0,9,1,1,5,7,4,2,7,4,7,7,5,4,2,6,2)
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36, train_orig)
plotTrain(1:36, test_orig)
test_orig_36 <- test_orig[1:36,]
test_orig_36$label <- c(2,0,9,0,3,7,0,3,0,3,5,7,4,0,4,3,3,1,9,0,9,1,1,5,7,4,2,7,4,7,7,5,4,2,6,2)
plotTrain(1:36, test_orig_36)
accuracy <- mean(predictions[1:36] == test_orig_36$label)
accuracy <- mean(predictions[1:36,] == test_orig_36$label)
print(paste('Accuracy:', accuracy))
View(predictions)
predictions[1:36,]
test_orig_36$label
# There is around 4000 observations for each digit. Each row has 784 columns
# (pixels) which form a 28x28 image. Let's see what the handwritten digits look
# like by plotting them. Here is a function to plot a selection of digits from
# the train dataset.
plotTrain <- function(images, ds, labels){
op <- par(no.readonly=TRUE)
x <- ceiling(sqrt(length(images)))
par(mfrow=c(x, x), mar=c(.1, .1, .1, .1))
for (i in images){ #reverse and transpose each matrix to rotate images
m <- matrix(data.matrix(ds[i,-1]), nrow=28, byrow=TRUE)
m <- apply(m, 2, rev)
image(t(m), col=grey.colors(255), axes=FALSE)
text(0.05, 0.2, col="white", cex=1.2, labels[i])
}
par(op) #reset the original graphics parameters
}
test_orig_36 <- test_orig[1:36,]
test_orig_36$label <- c(2,0,9,0,3,7,0,3,0,3,5,7,4,0,4,3,3,1,9,0,9,1,1,5,7,4,2,7,4,7,7,5,4,2,6,2)
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36, train_orig, train_orig$label)
plotTrain(1:36, test_orig_36, test_orig_36$label)
str(predictions)
plotTrain(1:36, test_orig_36, predictions$Label)
head(test_orig)
head(predictions)
predictions_36 <- predictions[1:36,2]
predictions_36
test_orig_36$label
predictions[1:36,] == test_orig_36$label
predictions_36 == test_orig_36$label
mean(predictions_36 == test_orig_36$label)
plotTrain(1:36, test_orig_36, predictions$Label)
head(test_orig)
predictions_36 <- predictions[1:36,2]
accuracy <- mean(predictions_36 == test_orig_36$label)
print(paste('Accuracy:', accuracy))
# split the training data into train and test to do local evaluation
set.seed(123)
rows <- sample(1:nrow(train_orig), as.integer(0.7*nrow(train_orig)))
# Get train and test labels
train_labels <- train_orig[rows, 1]
test_labels <- train_orig[-rows, 1]
# convert the labels to factors
train_labels <- as.factor(train_labels$label)
# custom normalization function
normalize <- function(x) {
return(x / 255)
}
# create the train and test datasets and apply normalization
train_norm <- as.data.frame(lapply(train_orig[rows, -1], normalize))
test_norm <- as.data.frame(lapply(train_orig[-rows,-1], normalize))
# check a random pixel to see if the normalization worked
summary(train_orig$pixel350)
summary(train_norm$pixel350)
summary(test_norm$pixel350)
# create the class indicator matrix
train_labels_matrix = class.ind(train_labels)
head(train_labels)
head(train_labels_matrix)
# train model
set.seed(123)
startTime <- proc.time()
nn = nnet(train_norm, train_labels_matrix, size = 1, softmax = TRUE)
## iter  30 value 55912.804141
## iter  40 value 54648.757612
## iter  50 value 53950.781576
## iter  60 value 52927.199756
## iter  70 value 52291.634751
## iter  80 value 51967.602466
## iter  90 value 51774.654787
## iter 100 value 51643.951402
## final  value 51643.951402
## stopped after 100 iterations
proc.time() - startTime
##    user  system elapsed
##   46.97    0.13   47.54
nn
pred = predict(nn, test_norm, type="class")
cbind(head(pred), head(test_labels))
View(test_labels)
# evaluate the model
accuracy <- mean(pred == test_labels)
print(paste('Accuracy:', accuracy))
par(mfrow=c(2,3)) # Plotting in 2*3 format (neural net)
lapply(1:6,
function(x) image( #norow = 28 because this is 28 pixel image
rotate(matrix(unlist(test_orig[x,]),nrow = 28,byrow = T)),
col=grey.colors(255),
xlab=pred[x]
)
)
# There is around 4000 observations for each digit. Each row has 784 columns
# (pixels) which form a 28x28 image. Let's see what the handwritten digits look
# like by plotting them. Here is a function to plot a selection of digits from
# the train dataset.
plotTrain <- function(images, ds, labels){
op <- par(no.readonly=TRUE)
x <- ceiling(sqrt(length(images)))
par(mfrow=c(x, x), mar=c(.1, .1, .1, .1))
for (i in images){ #reverse and transpose each matrix to rotate images
m <- matrix(data.matrix(ds[i,-1]), nrow=28, byrow=TRUE)
m <- apply(m, 2, rev)
image(t(m), col=grey.colors(255), axes=FALSE)
text(0.05, 0.2, col="white", cex=1.2, labels[i])
}
par(op) #reset the original graphics parameters
}
test_orig_36 <- test_orig[1:36,]
test_orig_36$label <- c(2,0,9,0,3,7,0,3,0,3,5,7,4,0,4,3,3,1,9,0,9,1,1,5,7,4,2,7,4,7,7,5,4,2,6,2)
# Now let's use this function to look at the first 36 images. You can look at
# many images if you wanted too, e.g., plotTrain(1001:1100)
plotTrain(1:36, train_orig, train_orig$label)
plotTrain(1:36, test_orig_36, test_orig_36$label)
# first we are going to try a random forest
numTrees <- 25
# Train on entire training dataset and predict on the test
startTime <- proc.time()
print(rf)
plot(rf,type="l")
# output predictions for submission
predictions <- data.frame(ImageId=1:nrow(test_orig),
Label=levels(train_orig_labels)[rf$test$predicted])
head(predictions)
rotate <- function(x) t(apply(x, 2, rev)) # reverses (rotates the matrix)
par(mfrow=c(2,3)) # Plotting in 2*3 format (random forest)
lapply(1:6,
function(x) image( #norow = 28 because this is 28 pixel image
rotate(matrix(unlist(test_orig[x,]),nrow = 28,byrow = T)),
col=grey.colors(255),
xlab=predictions[x,2]
)
)
plotTrain(1:36, test_orig_36, predictions$Label)
predictions_36 <- predictions[1:36,2]
accuracy <- mean(predictions_36 == test_orig_36$label)
print(paste('Accuracy:', accuracy))
rows <- sample(1:nrow(train_orig), as.integer(0.7*nrow(train_orig)))
# Get train and test labels
train_labels <- train_orig[rows, 1]
test_labels <- train_orig[-rows, 1]
# convert the labels to factors
train_labels <- as.factor(train_labels$label)
# custom normalization function
normalize <- function(x) {
return(x / 255)
}
# create the train and test datasets and apply normalization
train_norm <- as.data.frame(lapply(train_orig[rows, -1], normalize))
test_norm <- as.data.frame(lapply(train_orig[-rows,-1], normalize))
# check a random pixel to see if the normalization worked
summary(train_orig$pixel350)
summary(train_norm$pixel350)
summary(test_norm$pixel350)
# create the class indicator matrix
train_labels_matrix = class.ind(train_labels)
head(train_labels)
head(train_labels_matrix)
# train model
set.seed(123)
##    user  system elapsed
##   46.97    0.13   47.54
nn
# evaluate the model
accuracy <- mean(pred == test_labels)
print(paste('Accuracy:', accuracy))
par(mfrow=c(2,3)) # Plotting in 2*3 format (neural net)
lapply(1:6,
function(x) image( #norow = 28 because this is 28 pixel image
rotate(matrix(unlist(test_orig[x,]),nrow = 28,byrow = T)),
col=grey.colors(255),
xlab=pred[x]
)
)
