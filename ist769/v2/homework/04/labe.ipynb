{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b719a799-a9d8-4133-9bfa-964356169baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "#2 # 2 in spark\n",
    "# Create a new Spark notebook called labd.ipynb. Write (or copy and edit) Spark code to \n",
    "# set up the Spark session. Make sure your Spark session supports Minio access and \n",
    "# include the hadoop-aws Spark Jar package. Provide a screenshot of your code and the output.\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3d8f2b-565b-4ddd-ad62-8e3a799301a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://minio:9000\n"
     ]
    }
   ],
   "source": [
    "# MINIO CONFIGURATION\n",
    "s3_host = \"minio\"\n",
    "s3_url = f\"http://{s3_host}:9000\"\n",
    "s3_key = \"minio\"\n",
    "s3_secret = \"SU2orange!\"\n",
    "s3_bucket = \"labe\"\n",
    "print(s3_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bc3677-a77d-4ed9-b137-15708d0527dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2d5be1d0-082c-4843-8950-a53b66224ea6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.1.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.271 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.1.2/hadoop-aws-3.1.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.1.2!hadoop-aws.jar (99ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.271/aws-java-sdk-bundle-1.11.271.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.271!aws-java-sdk-bundle.jar (12395ms)\n",
      ":: resolution report :: resolve 3227ms :: artifacts dl 12501ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.271 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.1.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2d5be1d0-082c-4843-8950-a53b66224ea6\n",
      "\tconfs: [default]\n",
      "\t2 artifacts copied, 0 already retrieved (84646kB/101ms)\n",
      "23/02/03 14:36:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labe\n"
     ]
    }
   ],
   "source": [
    "# Spark init\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "    .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:3.1.2\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_url) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "print(s3_bucket)\n",
    "#sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46ce13f-67d5-4f5c-91ff-45fea0d0fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "+---------+----------------+-----------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------------------+-------------------------+------------------------+-------------------+--------------------+-------------------+-----------------+------------------+-----------------+---------------+----------+-------------+--------------+\n",
      "|      EST|Max TemperatureF|Mean TemperatureF|Min TemperatureF|Max Dew PointF|MeanDew PointF|Min DewpointF|Max Humidity|Mean Humidity|Min Humidity|Max Sea Level PressureIn|Mean Sea Level PressureIn|Min Sea Level PressureIn|Max VisibilityMiles|Mean VisibilityMiles|Min VisibilityMiles|Max Wind SpeedMPH|Mean Wind SpeedMPH|Max Gust SpeedMPH|PrecipitationIn|CloudCover|       Events|WindDirDegrees|\n",
      "+---------+----------------+-----------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------------------+-------------------------+------------------------+-------------------+--------------------+-------------------+-----------------+------------------+-----------------+---------------+----------+-------------+--------------+\n",
      "| 1997-1-1|              27|               12|              -2|            22|             4|           -8|          92|           74|          59|                   30.52|                    30.22|                   29.86|                 10|                   9|                  1|               14|                 5|             null|           0.05|         6|         Snow|            89|\n",
      "| 1997-1-2|              34|               28|              23|            33|            29|           21|         100|           96|          88|                   29.84|                    29.74|                   29.53|                  9|                   2|                  0|                8|                 4|             null|           0.08|         8|Fog-Rain-Snow|            82|\n",
      "| 1997-1-3|              44|               40|              36|            44|            38|           34|         100|           96|          89|                    29.9|                    29.68|                    29.5|                 10|                   4|                  0|               15|                 6|             null|           0.09|         8|     Fog-Rain|           273|\n",
      "| 1997-1-4|              48|               40|              34|            44|            36|           33|          96|           90|          83|                   29.99|                    29.87|                   29.62|                 10|                  10|                  8|               13|                 4|             null|           0.00|         8|         Rain|            80|\n",
      "| 1997-1-5|              55|               46|              37|            50|            43|           29|          89|           81|          73|                   29.62|                    29.45|                   29.29|                 10|                  10|                 10|               21|                11|               30|           0.13|         8|         Rain|           199|\n",
      "| 1997-1-6|              36|               32|              27|            26|            19|           13|          85|           63|          53|                   29.87|                    29.72|                   29.53|                 10|                   9|                  2|               29|                20|               36|           0.00|         8|         Snow|           262|\n",
      "| 1997-1-7|              28|               26|              23|            22|            15|           11|          91|           68|          49|                   30.01|                    29.89|                   29.83|                 10|                   5|                  0|               32|                20|               38|           0.01|         8|         Snow|           275|\n",
      "| 1997-1-8|              26|               22|              18|            16|            13|           10|          78|           69|          53|                   30.24|                    30.16|                   30.01|                 10|                   7|                  2|               22|                17|               32|           0.00|         6|         Snow|           287|\n",
      "| 1997-1-9|              25|               18|              10|            22|            14|            7|          92|           84|          69|                    30.2|                    29.82|                   29.36|                 10|                   7|                  1|               16|                 7|             null|           0.09|         7|         Snow|            83|\n",
      "|1997-1-10|              33|               29|              25|            28|            20|           12|          96|           70|          50|                   29.44|                    29.29|                   29.21|                 10|                   9|                  0|               22|                10|               28|           0.05|         8|         Snow|           225|\n",
      "|1997-1-11|              26|               22|              19|            15|            10|            8|          81|           63|          53|                   29.87|                    29.65|                   29.45|                 10|                   9|                  5|               31|                21|               36|           0.00|         7|         Snow|           250|\n",
      "|1997-1-12|              21|               20|              19|            14|            10|            8|          74|           65|          58|                   30.19|                    30.05|                   29.87|                 10|                   9|                  6|               31|                24|               36|           0.00|         7|         Snow|           252|\n",
      "|1997-1-13|              24|               22|              21|            21|            17|           14|          88|           77|          69|                   30.32|                    30.28|                   30.19|                 10|                   7|                  0|               22|                18|               29|           0.01|         8|         Snow|           254|\n",
      "|1997-1-14|              28|               24|              21|            18|            16|           12|          80|           72|          63|                   30.34|                    30.32|                   30.28|                 10|                   9|                  9|               22|                17|               28|           0.00|         8|         Snow|           254|\n",
      "|1997-1-15|              36|               24|              14|            19|            14|           10|          84|           60|          46|                   30.33|                    30.09|                    29.6|                 10|                  10|                 10|               18|                 9|             null|           0.00|         6|         null|           142|\n",
      "|1997-1-16|              39|               27|              12|            31|            19|            1|          88|           65|          47|                   29.66|                    29.46|                   29.35|                 10|                   9|                  1|               29|                20|               41|           0.02|         7|    Rain-Snow|           248|\n",
      "|1997-1-17|              12|                8|               3|             9|             0|           -8|          96|           70|          50|                   29.91|                    29.82|                   29.68|                 10|                   4|                  0|               28|                18|               33|           0.03|         7|         Snow|           267|\n",
      "|1997-1-18|               7|                2|              -2|             3|            -6|          -12|          84|           68|          53|                   30.17|                    29.98|                   29.78|                 10|                   6|                  1|               22|                14|               26|           0.02|         6|         Snow|           275|\n",
      "|1997-1-19|              18|                4|              -8|             2|            -3|          -13|          83|           63|          47|                   30.15|                    30.05|                   29.89|                 10|                   8|                  1|               16|                 7|             null|           0.03|         7|         Snow|           188|\n",
      "|1997-1-20|              32|               26|              19|            28|            19|            5|          93|           76|          50|                   30.14|                    29.87|                   29.75|                 10|                   6|                  1|               20|                11|               22|           0.03|         8|         Snow|           252|\n",
      "+---------+----------------+-----------------+----------------+--------------+--------------+-------------+------------+-------------+------------+------------------------+-------------------------+------------------------+-------------------+--------------------+-------------------+-----------------+------------------+-----------------+---------------+----------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "#Configure Spark to read from Minio labe bucket, then load \n",
    "#syracuse-ny.csv into a DataFrame and register  it as the table weather. \n",
    "s3_bucket =\"labe\"\n",
    "file_name = \"syracuse-ny.csv\"\n",
    "print(\"hello\")\n",
    "source = f\"s3a://{s3_bucket}/{file_name}\"\n",
    "weather = spark.read.option(\"header\", True).option(\"inferSchema\", True)\\\n",
    "    .csv(source)\n",
    "weather.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420774bb-9771-4f44-80cc-2e4327fc358d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |  weather|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = spark.read.option(\"header\", True).option(\"inferSchema\", True)\\\n",
    "    .csv(source)\n",
    "weather.createOrReplaceTempView(\"weather\")\n",
    "\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cadb700-9a7f-43d6-a425-315faa4bdbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- avgmintemp: double (nullable = true)\n",
      " |-- avgmaxtemp: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6 Rewrite Question 2 using pure Spark SQL and the weather temp view. NOTE: There will be some subtle \n",
    "#differences with how you must write the code, so be sure to printSchema() so you can see what the \n",
    "# columns are. \n",
    "query = '''\n",
    "WITH\n",
    "Source \n",
    "AS\n",
    "(\n",
    "\tSELECT \tcast(split(EST, '-')[0] AS int) AS year, \n",
    "\t        cast(split(EST, '-')[1] AS int) AS month, \n",
    "\t\t    cast(`Min TemperatureF` AS int) as mintemp, \n",
    "\t\t    cast(`Max TemperatureF` AS int) AS maxtemp\n",
    "\tFROM weather\n",
    ")\n",
    "SELECT year, month, AVG(mintemp) AS avgmintemp, AVG(maxtemp) AS avgmaxtemp\n",
    "FROM Source\n",
    "GROUP BY year, month\n",
    "ORDER BY year, month\n",
    "'''\n",
    "spark.sql(query).printSchema()\n",
    "weather2 = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc73458-0b80-424d-b694-9d3aabbf67a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:====================================================>  (192 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+------------------+\n",
      "|year|month|        avgmintemp|        avgmaxtemp|\n",
      "+----+-----+------------------+------------------+\n",
      "|1997|    1|15.774193548387096| 31.64516129032258|\n",
      "|1997|    2|22.607142857142858|37.785714285714285|\n",
      "|1997|    3|25.032258064516128| 41.12903225806452|\n",
      "|1997|    4| 34.43333333333333|              54.1|\n",
      "|1997|    5|43.096774193548384| 61.58064516129032|\n",
      "|1997|    6|              57.8|              78.4|\n",
      "|1997|    7| 59.87096774193548| 80.19354838709677|\n",
      "|1997|    8| 58.70967741935484| 78.38709677419355|\n",
      "|1997|    9| 51.06666666666667|              69.4|\n",
      "|1997|   10|38.935483870967744| 59.16129032258065|\n",
      "|1997|   11|31.466666666666665|42.666666666666664|\n",
      "|1997|   12|25.032258064516128|35.516129032258064|\n",
      "|1998|    1|23.258064516129032| 35.41935483870968|\n",
      "|1998|    2|24.142857142857142|              38.0|\n",
      "|1998|    3|30.129032258064516|45.064516129032256|\n",
      "|1998|    4|              38.0| 58.46666666666667|\n",
      "|1998|    5| 52.45161290322581|  73.6774193548387|\n",
      "|1998|    6|57.333333333333336|              75.3|\n",
      "|1998|    7| 61.29032258064516| 79.03225806451613|\n",
      "|1998|    8|              61.0| 81.09677419354838|\n",
      "+----+-----+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 7 Save the output from the DataFrame in Question 6 to the temp view \n",
    "# monthly_syracuse_weather_averages. Prove the view is there by querying it.\n",
    "\n",
    "weather2.createOrReplaceTempView(\"monthly_syracuse_weather_averages\")\n",
    "query2 = '''\n",
    "SELECT * FROM monthly_syracuse_weather_averages\n",
    "'''\n",
    "spark.sql(query2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fb23298-d7c8-4dca-b229-c285ed9dcb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H1>Syracuse Weather</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f974d75e382b466380403ec593d9ebf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=6, description='Month', max=12, min=1), Button(description='Run Interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. CHALLENGE YOURSELF! At the bottom of the work/content/E-Drill-Spark.ipynb file there is a section \n",
    "#called Big Data to Small Data. Try to write a complete program that:\n",
    "# a. Inputs a month 1–12 at run-time\n",
    "# b. Displays a scatter plot of min/max average monthly temperatures, where year is on the X-axis\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import interact_manual\n",
    "\n",
    "display(HTML(\"<H1>Syracuse Weather</h1>\"))\n",
    "@interact_manual(Month=(1,12))\n",
    "def showResult(Month):\n",
    "    df = spark.sql(f\"select * from monthly_syracuse_weather_averages WHERE month = {Month}\").toPandas()\n",
    "    display(df)\n",
    "    display(df.plot(x=\"year\", y=\"avgmintemp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "283e9625-6989-4422-9484-0a4f7c69dacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H1>Syracuse Weather</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bb994f2d4f437a8bb9985164b47106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=6, description='Month', max=12, min=1), Button(description='Run Interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "display(HTML(\"<H1>Syracuse Weather</h1>\"))\n",
    "@interact_manual(Month=(1,12))\n",
    "def showResult2(Month):\n",
    "    df = spark.sql(f\"select * from monthly_syracuse_weather_averages WHERE month = {Month}\").toPandas()\n",
    "    df.set_index(\"year\")\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.scatter(df[\"year\"],y=df[\"avgmintemp\"], label='monthly avg min', marker='v')\n",
    "    plt.scatter(df[\"year\"],y=df[\"avgmaxtemp\"], label='monthly avg max', marker='^')\n",
    "    plt.legend(title=f\"Temperatures for Month {Month}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc60aa-93c0-486b-8380-9c6647713872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
