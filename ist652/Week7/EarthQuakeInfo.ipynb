{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " # get the bbc rss feed of news stories and connect to it\n",
    "earthquake_url = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/significant_month.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_earthquakes():\n",
    "    try:\n",
    "        response = urllib.request.urlopen(earthquake_url)\n",
    "    except urllib.error.URLError as e:\n",
    "        if hasattr(e, 'reason'):\n",
    "            print('We failed to reach a server.')\n",
    "            print('Reason: ', e.reason)\n",
    "        elif hasattr(e, 'code'):\n",
    "            print('The server couldn\\'t fulfill the request.')\n",
    "            print('Error code: ', e.code)\n",
    "    else:\n",
    "        # the url request was successful - convert the response to a string\n",
    "        json_string = response.read().decode('utf-8')\n",
    "\n",
    "        # the json package loads() converts the string to python dictionaries and lists\n",
    "        eq_json = json.loads(json_string)\n",
    "\n",
    "        # from the json dictionary we get the title to print\n",
    "        title = eq_json['metadata']['title']\n",
    "        print('Collected data from', title)\n",
    "        #  and we get the list of earthquakes\n",
    "        quakelist = eq_json['features']\n",
    "\n",
    "        # Connection to Mongo DB\n",
    "        try:\n",
    "            client=pymongo.MongoClient('localhost', 27017)\n",
    "            print (\"Connected successfully!!!\")\n",
    "        except pymongo.errors.ConnectionFailure as e:\n",
    "           print (\"Could not connect to MongoDB: %s\" % e )\n",
    "        else:\n",
    "\n",
    "            # use database named usgs or create it if not there already\n",
    "            eqdb = client.usgs\n",
    "            # create collection named earthquakes or create it if not there already\n",
    "            quakecoll = eqdb.earthquakes\n",
    "            # add all the earthquakes to the list\n",
    "            quakecoll.insert_many(quakelist)\n",
    "            print(\"Added\", len(quakelist), \"to earthquakes collection in usgs database\")\n",
    "            # close the database connection\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earthquakes():\n",
    "    quake_docs = []\n",
    "    # Connection to Mongo DB\n",
    "    try:\n",
    "        client=pymongo.MongoClient('localhost', 27017)\n",
    "        print (\"Connected successfully!!!\")\n",
    "    except pymongo.errors.ConnectionFailure as e:\n",
    "        print (\"Could not connect to MongoDB: %s\" % e )\n",
    "    else:\n",
    "        # use database named usgs or create it if not there already\n",
    "        eqdb = client.usgs\n",
    "        # create collection named earthquakes or create it if not there already\n",
    "        quakecoll = eqdb.earthquakes\n",
    "        # add all the earthquakes to the list\n",
    "        for doc in quakecoll.find():\n",
    "            place = doc[\"properties\"][\"place\"]\n",
    "            # grab unix timestamp in milliseconds\n",
    "            unix_time_mil = doc[\"properties\"][\"time\"]\n",
    "            # convert to unix in seconds\n",
    "            unix_time = unix_time_mil / 1000\n",
    "            quake_docs.append([place,unix_time])\n",
    "            \n",
    "        # close the database connection\n",
    "    client.close()\n",
    "    quake_docs = pd.DataFrame(quake_docs)\n",
    "    quake_docs.columns = ['Location','Time']\n",
    "    quake_docs['Time'] = quake_docs.Time.apply(lambda unix_time: datetime.datetime.fromtimestamp(unix_time).isoformat())\n",
    "    return quake_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_earthquakes():\n",
    "    quake_docs = get_earthquakes()\n",
    "    print(quake_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!!!\n",
      "                              Location                        Time\n",
      "0             16km SE of Su'ao, Taiwan  2019-08-07T17:28:02.548000\n",
      "1             54km ENE of Namie, Japan  2019-08-04T06:23:03.862000\n",
      "2   102km WSW of Tugu Hilir, Indonesia  2019-08-02T08:03:27.483000\n",
      "3        94km SW of San Antonio, Chile  2019-08-01T14:28:05.073000\n",
      "4          62km E of Lakatoro, Vanuatu  2019-07-31T11:02:33.851000\n",
      "5   24km S of La Libertad, El Salvador  2019-07-31T01:54:55.289000\n",
      "6           140km ESE of Shingu, Japan  2019-07-27T14:31:07.514000\n",
      "7       16km S of Twentynine Palms, CA  2019-07-22T12:26:56.080000\n",
      "8           3km NNW of Magoula, Greece  2019-07-19T07:13:16.136000\n",
      "9                12km WSW of Byron, CA  2019-07-16T16:11:01.470000\n",
      "10   36km SSE of Kendalrejo, Indonesia  2019-07-15T20:18:36.991000\n",
      "11            16km SE of Su'ao, Taiwan  2019-08-07T17:28:02.548000\n",
      "12            54km ENE of Namie, Japan  2019-08-04T06:23:03.862000\n",
      "13  102km WSW of Tugu Hilir, Indonesia  2019-08-02T08:03:27.483000\n",
      "14       94km SW of San Antonio, Chile  2019-08-01T14:28:05.073000\n",
      "15         62km E of Lakatoro, Vanuatu  2019-07-31T11:02:33.851000\n",
      "16  24km S of La Libertad, El Salvador  2019-07-31T01:54:55.289000\n",
      "17          140km ESE of Shingu, Japan  2019-07-27T14:31:07.514000\n",
      "18      16km S of Twentynine Palms, CA  2019-07-22T12:26:56.080000\n",
      "19          3km NNW of Magoula, Greece  2019-07-19T07:13:16.136000\n",
      "20               12km WSW of Byron, CA  2019-07-16T16:11:01.470000\n",
      "21   36km SSE of Kendalrejo, Indonesia  2019-07-15T20:18:36.991000\n",
      "22            16km SE of Su'ao, Taiwan  2019-08-07T17:28:02.548000\n",
      "23            54km ENE of Namie, Japan  2019-08-04T06:23:03.862000\n",
      "24  102km WSW of Tugu Hilir, Indonesia  2019-08-02T08:03:27.483000\n",
      "25       94km SW of San Antonio, Chile  2019-08-01T14:28:05.073000\n",
      "26         62km E of Lakatoro, Vanuatu  2019-07-31T11:02:33.851000\n",
      "27  24km S of La Libertad, El Salvador  2019-07-31T01:54:55.289000\n",
      "28          140km ESE of Shingu, Japan  2019-07-27T14:31:07.514000\n",
      "29      16km S of Twentynine Palms, CA  2019-07-22T12:26:56.080000\n",
      "30          3km NNW of Magoula, Greece  2019-07-19T07:13:16.136000\n",
      "31               12km WSW of Byron, CA  2019-07-16T16:11:01.470000\n",
      "32   36km SSE of Kendalrejo, Indonesia  2019-07-15T20:18:36.991000\n"
     ]
    }
   ],
   "source": [
    "list_earthquakes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
